# Tinystories Unlearning - Detailed Guide

This directory covers all Tinystories unlearning results. This `README_verbose.md` provides a more detailed guide on how to train models and perform unlearning experiments compared to the original `README.md`.

The main experiment logic (model pretraining and some unlearning methods) is in `tinystories_era.py`. This is called by `bulk_runs_for_paper.py` and `bulk_runs_partial_oversight.py` to configure and orchestrate multiple runs.
Another unlearning method, Representation Matching Unlearning (RMU), is implemented in `rmu.py`.
High-level configurations shared across all runs are specified in `shared_settings.py`.
Scripts starting with `analyze_*` read CSVs generated by other scripts to produce tables/figures.
Scripts starting with `explore_*` are for exploratory data analysis.

## Setup

It's assumed you have a Python environment with the necessary dependencies installed. The scripts use libraries like PyTorch, TransformerLens, WandB, and the Hugging Face `datasets` library. Refer to project-level dependency files if available (e.g., `pyproject.toml` if using PDM/Poetry).

To activate a PDM virtual environment (if used):
```bash
pdm venv activate
```

## Dataset

The primary dataset used in these experiments is `"delphi-suite/stories"` from the Hugging Face Hub. It is typically loaded using the `datasets.load_dataset` function.

For example, in `shared_settings.py`:
```python
cfg = SharedExperimentConfig(
    # ... other parameters ...
    total_num_stories_to_load=500_000,  # delphi-suite/stories has 2_705_118 stories
    # ...
)
# ...
# and later in a test section of shared_settings.py:
# dataset = load_dataset("delphi-suite/stories", split="train")
```

Different scripts might use the "train" or "validation" splits and may load a subset of the total available stories (e.g., `total_num_stories_to_load` in `shared_settings.cfg`).

## Training a Base Model

While specific scripts for training a base model from scratch aren't explicitly detailed as separate from unlearning runs, the `tinystories_era.py` script can be configured to train a model that serves as a base.

The `do_era_training_run` function in `tinystories_era.py` is the core function for these runs.
To train a "base" model (i.e., standard training without unlearning-specific modifications):
1.  Configure a `RunTypeConfig` in `shared_settings.py` (or create one dynamically in a script like `bulk_runs_for_paper.py`).
    *   Set `label` (e.g., "base_model").
    *   Set `pretrained_model_to_load=None` to train from scratch (or specify a starting checkpoint).
    *   Set `expand_model=False`.
    *   Set `use_gradient_routing=False`.
    *   Set `num_steps_coherence_finetuning=0` and `num_steps_forget_set_retraining=0`.
    *   Set `l1_coeff=0`.
2.  Configure an `ERAConfig` (though many of its parameters will be irrelevant if `expand_model=False` and `use_gradient_routing=False`). A minimal one would suffice.
3.  Use a script (like `bulk_runs_for_paper.py` as a template) to call `tinystories_era.do_era_training_run` with your desired `SharedExperimentConfig`, the new `RunTypeConfig`, and `ERAConfig`.

Example of a base model configuration from `bulk_runs_for_paper.py`:
```python
base_model_cfg = shared_settings.RunTypeConfig(
    label="base",
    pretrained_model_to_load=None,
    anneal_gradient_mask_weights=False,
    mask_weight_increase_steps=0,
    expand_model=False,
    use_gradient_routing=False,
    forget_data_labeling_percentage=1.0, # For base model, this data split might not be used for unlearning objective
    drop_labeled_forget_data=False,
    drop_unlabeled_forget_data=False,
    sort_forget_data_by_label=False,
    num_steps_era_training=era_steps, # Total training steps
    num_steps_coherence_finetuning=0,
    num_steps_forget_set_retraining=0,
    l1_coeff=0,
)
```
You would then call `do_era_training_run` providing this configuration. The `num_steps_era_training` would correspond to the total number of training steps for this base model.

## Performing ERA-style Unlearning (ERAC, DEMIX)

Error Reduction Analysis and Control (ERAC) and DEMIX are unlearning techniques implemented within `tinystories_era.py`. These methods typically involve modifying the model (e.g., expanding dimensions) and using gradient routing or specific masking schemes during training to make the model "forget" certain information (defined by "forget sets") while retaining other information ("retain sets").

**Key Concepts:**
*   **Forget/Retain Sets:** Data is typically split based on concepts to be unlearned (e.g., stories containing specific `words_to_localize` from `shared_settings.py`).
*   **Masking:** Techniques (`ddbp`, `slgr`, `demix` specified in `ERAConfig.masking_type`) are used to selectively update or steer parts of the model. Masking can be applied to full sequences or specific concepts (`ERAConfig.masking_scheme`).
*   **Model Expansion:** Some methods like ERAC might involve expanding parts of the model (e.g., MLP layers, `ERAConfig.to_expand`).
*   **Gradient Routing:** Directs updates towards or away from certain representations.

**How to run:**
1.  **Define Configurations in `shared_settings.py` (or dynamically):**
    *   `SharedExperimentConfig (cfg)`: Defines global parameters like model name, batch size, learning rate, `words_to_localize` (defining the forget concept).
    *   `ERAConfig`: Defines parameters specific to the ERA method.
        *   `layers_to_mask`: Which layers to apply unlearning modifications.
        *   `to_expand`: Dictionary specifying how to expand model dimensions (e.g., `{"d_mlp": 64}`).
        *   `masking_scheme`: E.g., "full_seq", "concept".
        *   `masking_type`: E.g., "ddbp" (Directional Damping Before Propagation), "demix".
        *   `expanded_vs_original_dim_learning_rates`: Learning rates for different parts of an expanded model.
    *   `RunTypeConfig`: Defines parameters for a specific type of run.
        *   `label`: A descriptive name (e.g., "ERAC_forest_unlearning").
        *   `pretrained_model_to_load`: Path to the base model you want to unlearn from.
        *   `expand_model=True` (usually for ERAC).
        *   `use_gradient_routing=True` (usually for ERAC).
        *   `forget_data_labeling_percentage`: Proportion of forget data that is actually labeled as forget.
        *   `num_steps_era_training`: Number of steps for the main unlearning phase.
        *   `num_steps_coherence_finetuning`, `num_steps_forget_set_retraining`: Optional additional fine-tuning phases.
        *   `l1_coeff`: L1 regularization coefficient, if applicable.

2.  **Use a script to call `tinystories_era.do_era_training_run`:**
    The `bulk_runs_for_paper.py` script provides examples of how to set up and run these experiments. It defines various `RunTypeConfig` and `ERAConfig` instances and then calls `do_era_training_run`.

    Example `ERAConfig` from `bulk_runs_for_paper.py` for ERAC-like method:
    ```python
    era_cfg = shared_settings.ERAConfig(
        layers_to_mask=[0, 1, 2, 3, 4],
        to_expand={"d_mlp": 64},
        masking_scheme="full_seq",
        masking_type="ddbp",
        expanded_vs_original_dim_learning_rates=dict(...),
        include_conditional_bias_term=False,
    )
    ```

    Example `RunTypeConfig` from `bulk_runs_for_paper.py` for ERAC:
    ```python
    erac_model_cfg = shared_settings.RunTypeConfig(
        label="ERAC",
        pretrained_model_to_load=None, # Should be path to a trained base model
        # ... other params ...
        expand_model=True,
        use_gradient_routing=True,
        # ...
    )
    ```

3.  **Execution:**
    Modify or create a script similar to `bulk_runs_for_paper.py` to point to your desired base model and configurations. Then run the script:
    ```bash
    python projects/tinystories/your_custom_era_script.py
    ```
    Or for a dry run (to test configuration without actual training/W&B logging):
    ```bash
    python projects/tinystories/your_custom_era_script.py dry_run
    ```

## Performing RMU (Representation Matching Unlearning)

Representation Matching Unlearning (RMU) is another unlearning technique implemented in `rmu.py`. It aims to make a model "forget" specific information by steering the activations of chosen layers towards a random vector for "forget" data, while simultaneously trying to keep the activations for "retain" data close to those of an original, frozen copy of the model.

**How to run:**
The `rmu.py` script can be run directly. It contains a `do_rmu_training_run` function that handles the unlearning process.

1.  **Key Parameters for `do_rmu_training_run` (many are set within the script or can be passed as arguments if modified):**
    *   `model_to_load`: Path to the pre-trained model you want to apply RMU to.
    *   `model_save_dir`, `model_save_name`: Where to save the unlearned model.
    *   `num_training_steps`: Number of RMU training steps.
    *   `layers_to_train`: List of layer indices whose parameters will be updated during RMU (e.g., `[5, 6, 7]`). These are the layers *whose parameters are being changed*.
    *   `param_pattern`: Pattern to match parameter names within the `layers_to_train` (e.g., "mlp" or "attn").
    *   `target_layer`: The layer *whose activations are being steered* for the RMU objective (e.g., `7`). This is where the RMU loss is computed.
    *   `steering_coef`: Coefficient for the forget loss component (how strongly to steer towards the random vector).
    *   `retain_wt` (alpha in RMU papers): Weight for the retain loss component (how strongly to penalize deviation from the frozen model's activations on retain data).
    *   `learning_rate`: Learning rate for the RMU optimizer.
    *   `forget_data_labeling_pct`: Percentage of stories identified by `words_to_localize` to be used in the forget set. The rest are added to the retain set.
    *   `shared_settings.cfg.words_to_localize`: Defines the concept to forget.

2.  **Execution:**
    You can run `rmu.py` from the command line. You might need to modify the script to easily pass all parameters or set them directly within its `if __name__ == "__main__":` block.
    ```bash
    python projects/tinystories/rmu.py
    ```
    For a dry run:
    ```bash
    python projects/tinystories/rmu.py dry_run
    ```
    The script uses `shared_settings.cfg` for some parameters (like `words_to_localize`, `batch_size`, `transformer_lens_model_name`). You may need to adjust these in `shared_settings.py` or modify `rmu.py` to override them.

## Orchestrating Bulk Runs

*   `bulk_runs_for_paper.py`: This script is designed to run multiple ERA-style unlearning experiments (using `tinystories_era.py`) with different configurations and random seeds. It's a good template for running systematic experiments.
*   `bulk_runs_partial_oversight.py`: Similar to `bulk_runs_for_paper.py`, but likely configured for experiments focusing on partial oversight (where not all "forget" data is explicitly labeled as such).
*   `bulk_runs_hyperparam_sweep.py`: Suggests a script for hyperparameter sweeps, likely also calling into `tinystories_era.py`.

These scripts typically:
1.  Define several `RunTypeConfig` and `ERAConfig` objects.
2.  Loop through these configurations and random seeds.
3.  Call `tinystories_era.do_era_training_run` for each combination.
4.  Save models to a specified directory, often with names indicating the configuration and seed.

## Key Configuration File: `shared_settings.py`

This file is central to most operations. It defines:
*   `SharedExperimentConfig`: Dataclass holding common experimental parameters (model, data, training, evaluation terms). An instance `cfg` is created with default values.
*   `ERAConfig`: Dataclass for parameters specific to ERA-style unlearning methods.
*   `RunTypeConfig`: Dataclass to define specifics of a particular run type (e.g., base training, ERAC, DEMIX), including which model to load, whether to expand the model, use gradient routing, and training step counts for different phases.

Adjusting parameters in `shared_settings.py` (especially in the `cfg` instance or by creating new config objects) is the primary way to customize experiments.

## Analysis and Exploration

As mentioned in the original `README.md`:
*   Any script starting with `analyze_*` (e.g., `analyze_bulk_runs.py`, `analyze_partial_oversight_runs.py`) reads in a CSV file generated by one of the training/unlearning scripts (which often log metrics) and produces tables, figures, or further analysis based on it.
*   Any script starting with `explore_*` (e.g., `explore_token_counts.py`, `explore_model_generations.py`) is intended for more ad-hoc exploratory data analysis and typically has fewer dependencies on the main experimental pipeline.

These scripts are essential for understanding the results of your training and unlearning experiments. 